---
layout: post
title : HTS的介绍与安装
cover : 
tags  : HTS HMM
---
<h3>HTS - HMM-based speech synthesis system</h3>

HTS是什么？

HTS官网上这样说：

<blockquote>
  Introduction
  Over the last ten years, the quality of speech synthesis has drastically improved with the rise of general corpus-based speech synthesis. Especially, state-of-the-art unit selection speech synthesis can generate natural-sounding high quality speech. However, for constructing human-like talking machines, speech synthesis systems are required to have an ability to generate speech with arbitrary speaker's voice characteristics, various speaking styles including native and non-native speaking styles in different languages, varying emphasis and focus, and/or emotional expressions; it is still difficult to have such flexibility with unit-selection synthesizers, since they need a large-scale speech corpus for each voice.
  
  In recent years, a kind of statistical parametric speech synthesis based on hidden Markov models (HMMs) has been developed. The system has the following features:
  
  Original speaker's voice characteristics can easily be reproduced because all speech features including spectral, excitation, and duration parameters are modeled in a unified framework of HMM, and then generated from the trained HMMs themselves.
  Using a very small amount of adaptation speech data, voice characteristics can easily be modified by transforming HMM parameters by a speaker adaptation technique used in speech recognition systems. From these features, the HMM-based speech synthesis approach is expected to be useful for constructing speech synthesizers which can give us the flexibility we have in human voices.
  
  In this tutorial, the system architecture is outlined, and then basic techniques used in the system, including algorithms for speech parameter generation from HMM, are described with simple examples. Relation to the unit selection approach, trajectory modeling, recent improvements, and evaluation methodologies are are summarized. Techniques developed for increasing the flexibility and improving the speech quality are also reviewed.
</blockquote>

说简单点，HTS就是一个基于参数合成的基于隐马尔可夫模型（Hidden Markov Model，HMM）的一个语料库语音合成系统。

<h3>隐马尔可夫模型（Hidden Markov Model，HMM）</h3>

隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。

HMM（隐马尔可夫模型）是用来描述隐含未知参数的统计模型，举一个经典的例子：一个东京的朋友每天根据天气{下雨，天晴}决定当天的活动{公园散步,购物,清理房间}中的一种，我每天只能在twitter上看到她发的推“啊，我前天公园散步、昨天购物、今天清理房间了！”，那么我可以根据她发的推特推断东京这三天的天气。在这个例子里，显状态是活动，隐状态是天气。

任何一个HMM都可以通过下列五元组来描述：

obs | 观测序列
- | -
states | 隐状态
start_p | 初始概率（隐状态）
trans_p | 转移概率（隐状态）
emit_p | 发射概率 （隐状态表现为显状态的概率）


下面用一个简单的例子来阐述：

假设我手里有三个不同的骰子。第一个骰子是我们平常见的骰子（称这个骰子为D6），6个面，每个面（1，2，3，4，5，6）出现的概率是1/6。第二个骰子是个四面体（称这个骰子为D4），每个面（1，2，3，4）出现的概率是1/4。第三个骰子有八个面（称这个骰子为D8），每个面（1，2，3，4，5，6，7，8）出现的概率是1/8。

假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是1/3。然后我们掷骰子，得到一个数字，1，2，3，4，5，6，7，8中的一个。不停的重复上述过程，我们会得到一串数字，每个数字都是1，2，3，4，5，6，7，8中的一个。例如我们可能得到这么一串数字（掷骰子10次）：1 6 3 5 2 7 3 5 2 4

这串数字叫做可见状态链。但是在隐马尔可夫模型中，我们不仅仅有这么一串可见状态链，还有一串隐含状态链。在这个例子里，这串隐含状态链就是你用的骰子的序列。比如，隐含状态链有可能是：D6 D8 D8 D6 D4 D8 D6 D6 D4 D8

一般来说，HMM中说到的马尔可夫链其实是指隐含状态链，因为隐含状态（骰子）之间存在转换概率（transition probability）。在我们这个例子里，D6的下一个状态是D4，D6，D8的概率都是1/3。D4，D8的下一个状态是D4，D6，D8的转换概率也都一样是1/3。这样设定是为了最开始容易说清楚，但是我们其实是可以随意设定转换概率的。比如，我们可以这样定义，D6后面不能接D4，D6后面是D6的概率是0.9，是D8的概率是0.1。这样就是一个新的HMM。

同样的，尽管可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（emission probability）。就我们的例子来说，六面骰（D6）产生1的输出概率是1/6。产生2，3，4，5，6的概率也都是1/6。我们同样可以对输出概率进行其他定义。比如，我有一个被赌场动过手脚的六面骰子，掷出来是1的概率更大，是1/2，掷出来是2，3，4，5，6的概率是1/10。

其实对于HMM来说，如果提前知道所有隐含状态之间的转换概率和所有隐含状态到所有可见状态之间的输出概率，做模拟是相当容易的。但是应用HMM模型时候呢，往往是缺失了一部分信息的，有时候你知道骰子有几种，每种骰子是什么，但是不知道掷出来的骰子序列；有时候你只是看到了很多次掷骰子的结果，剩下的什么都不知道。如果应用算法去估计这些缺失的信息，就成了一个很重要的问题。

<h3>HTS的模块</h3>

<ul>
<li>Hidden semi-Markov model 隐半马尔可夫模型（HSMM）：<br/>
为HTS提供训练，适应，合成的功能。</li>
<li>Multi-space probability distribution for F0 F0的最大空间概率分布<br/>
提供每帧的F0值为零或非零。</li>
<li>Tree-based clustering based on the MDL criterion 基于MDL标准的基于树的聚类<br/>
其中的MDL是最小描述长度的意思（因为HTK采用ML标准）</li>
<li>Global variance 全局方差 (GV)<br/>
让HTS可以缓解低沉的声音和平滑过度声音。</li>
</ul>

<h3>下载，安装HTS</h3>

软件环境需求:

<ul>
<li>HTK &amp; HDecode <br/>
http://htk.eng.cam.ac.uk/</li>
<li>HTS patch for HTK <br/>
http://hts.sp.nitech.ac.jp/?Download</li>
<li>HTS Engine API  <br/>
http://hts-engine.sourceforge.net/</li>
<li>SPTK <br/>
http://sp-tk.sourceforge.net/</li>
<li>HTS training demo (Japanese or English) <br/>
http://hts.sp.nitech.ac.jp/?Download</li>
</ul>

下载编译安装即可

<h3>HTS目录结构</h3>

<h4>HTS的目录</h4>

<ul>
<li>/configs<br/>
训练中使用的配置文件。</li>
<li>/edfiles<br/>
编辑HHEd使用的文件，负责HMM的模型操作</li>
<li>/gen<br/>
合成的声音（在这里查看你的结果！）</li>
<li>/models<br/>
训练中的HTK模型</li>
<li>/proto<br/>
原型HMM，仅在训练开始时使用</li>
<li>/stats<br/>
有关训练的统计文件，例如“发生次数和平均占用次数”</li>
<li>/tree<br/>
HTK格式的决策树聚类</li>
<li>/voices<br/>
HTS格式的模型</li>
<li>/scripts<br/>
负责训练的脚本: Config.pm 和 Training.pl</li>
<li>/data<br/>
训练数据，其中目录结构见“Data目录”</li>
</ul>

<h4>Data目录</h4>

<ul>
<li>波形与音频特性<br/>
/data/raw : 去除Wav标签的wav文件（raw格式）<br/>
/data/mgc (或者 /mcp): mel频谱特征<br/>
/data/lf0 : 对数基频<br/>
/data/gv : 关于MGC和LF0的全局方差 <br/>
/data/cmp : 合成特性 (MGC+LF0)<br/></li>
<li>其他文件<br/>
/data/scp : 训练/合成的列表 <br/>
/data/win : 特征提取中使用的参数 <br/>
/data/scripts : 数据准备中使用的脚本<br/></li>
<li>label文件<br/>
目录结构见“label目录”</li>
</ul>

<h4>label目录</h4>

<ul>
<li>/data/labels/mono<br/>
单声道标签文件（标签需要包含时间信息，因为HRest需要它。）<br/></li>
<li>/data/labels/full<br/>
依赖于上下文的标签文件（时间信息可以省略。）<br/></li>
<li>/data/labels/gen<br/>
用于合成的依赖于上下文的标签文件</li>
<li>/data/questions<br/>
决策树聚类中使用的问题集</li>
<li>/data/lists<br/>
不同的标签（不知道怎么翻译：distinct labels）</li>
</ul>

引用文章：<br/>
https://www.cnblogs.com/skyme/p/4651331.html<br/>
H. Zen et al., Recent development of the HMM-based speech
synthesis system (HTS) <br/>
T. Yoshimura, K. Tokuda, T. Masuko, T. Kobayashi, and T. Kitamura.
Simultaneous modeling of spectrum, pitch and duration in HMM-based
speech synthesis. In Proc. Eurospeech, pages 2347–2350, 1999.<br/>
J. Yamagishi. Average-Voice-Based Speech Synthesis. PhD thesis, Tokyo
Institute of Technology, 2006.<br/>
T. Yoshimura, T. Masuko, K. Tokuda, T. Kobayashi, and T. Kitamura.
Speaker interpolation for HMM-based speech synthesis system. J.
Acoust. Soc. Jpn. (E), 21(4):199–206, 2000.<br/>
K. Shichiri, A. Sawabe, K. Tokuda, T. Masuko, T. Kobayashi, and
T. Kitamura. Eigenvoices for HMM-based speech synthesis. In Proc.
ICSLP, pages 1269–1272, 2002.<br/>
K. Tokuda, H. Zen, J. Yamagishi, T. Masuko, S. Sako, T. Toda, A.W.
Black, T. Nose, and K. Oura. The HMM-based speech synthesis system
(HTS). http://hts.sp.nitech.ac.jp/.<br/>
R. Sproat, J. Hirschberg, and D. Yarowsky. A corpus-based synthesizer.
In Proc. ICSLP, pages 563–566, 1992.<br/>